---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# queuebee <a href=''><img src='' align="right" height="200" /></a>

<!-- badges: start -->
<!-- badges: end -->

## Overview




## Installation

Install the official version from CRAN:

```{r, eval=FALSE}
# install.packages("queuebee")
```

Install the latest development version from github:

```{r, eval=FALSE}
devtools::install_github("EhrmannS/queuebee")
```


## Examples

```{r example}
library(dplyr, warn.conflicts = FALSE)
library(queuebee)
```

Let's first build an example dataset

```{r}
input <- tibble(x = sample(seq(23.3, 28.1, 0.1), 10),
                y = sample(seq(57.5, 59.6, 0.1), 10),
                year = rep(2021, 10),
                commodity = rep(c("soybean", "maize"), 5),
                landuse = sample(c("crop", "grazing", "forest"), size = 10, replace = TRUE),
                some_other = rnorm(10))

# make it have some errors
input$x[5] <- 259
input$x[9] <- 0
input$y[10] <- NA_real_
input$y[9] <- 0
input$year[c(2:3)] <- c(NA, "2021r")
input$commodity[c(3, 5)] <- c(NA_character_, "dog")

# derive valid values for commodities
validComm <- c("soybean", "maize")
```

The first step in yielding quality bits is in creating a bitfield.

  1. The `width = ` specifies how many bits are in the bitfield.
  2. The `lenght = ` specifies how long the output table is. Any input must then have the same length. In case there are inputs with a different length, make sure in your pre-processing steps that all inputs are joined/merged that empty values or NAs are explicit.
  3. The `name = ` specifies the label of the bitfield, which becomes very important when publishing, because bitfield and output table are stored in different files and it must be possible to unambiguously associate them to one another.

```{r}
newBitfield <- qb_create(width = 10, length = dim(input)[1])
```

Then, individual bits need to be grown by specifying from which input and based on which mapping function a particular position of the bitfield should be modified. When providing a concise yet expressive description, you will also in the future still understand what you did here.

```{r, eval = FALSE}
newBitfield <- newBitfield %>%
  # explicit tests for coordinates ...
  qb_grow(bit = qb_na(x = input, test = "x"), name = "is_na_x",
          desc = c("x-coordinate values do not contain any NAs"),
          pos = 1, bitfield = .) %>%
  qb_grow(bit =  qb_range(x = input, test = "x", min = -180, max = 180), name = "range_1_x",
          desc = c("x-coordinate values are numeric and within the valid WGS84 range"),
          pos = 2, bitfield = .) %>%
  # ... or override NA test
  qb_grow(bit = qb_range(x = input, test = "y", min = -90, max = 90), name = "range_1_y",
          desc = c("y-coordinate values are numeric and within the valid WGS84 range, NAs are FALSE"),
          pos = 3, na = FALSE, bitfield = .) %>%
  # it is also possible to use other functions that give flags, such as from CoordinateCleaner ...
  qb_grow(bit = cc_equ(x = input, lon = "x", lat = "y", value = "flagged"), name = "equal_coords",
          desc = c("x and y coordinates are not identical"),
          pos = 4, bitfield = .) %>%
  # ... or stringr ...
  qb_grow(bit = str_detect(input$year, "r"), name = "flag_year",
          desc = c("year values do have a flag"),
          pos = 6, bitfield = .) %>%
  # ... or even base R
  qb_grow(bit = is.na(as.integer(input$year)), name = "is_na_year",
          desc = c("year values are valid integers"),
          pos = 5, bitfield = .)  %>%
  # test for matches with an external vector
  qb_grow(bit = qb_match(x = input, test = "commodity", against = validComm), name = "match_commodities",
          desc = c("commodity values are part of 'soybean' or 'maize'"),
          pos = 7, na = FALSE, bitfield = .) %>%
  # define cases
  qb_grow(bit = qb_case(x = input, some_other > 0.5, some_other > 0, some_other < 0), name = "cases_some_other",
          desc = c("some_other values are distinguished into large, medium and small"),
          pos = 8:9, bitfield = .)
```

This strcuture is basically a record of all the things that are grown on a bitfield, but so far nothing has happened

```{r, eval = FALSE}
newBitfield
```

To make things happen eventually, the bitfield and a(ny) input it shall be applied to are combined. This will result in an output table (with one column that has the name `QB`) with the same length as the longest column in the inputs. When bit flags are grown from inputs with different length, a join/merge column needs to be provided.

```{r, eval = FALSE}
qb_combine(bitfield = newBitfield)
```

Anybody that wants to either extend the bitfield or analyse the output data and base their judgement on the quality bit will want to extract that bit. The bitfield is thereby the key that is required to decode the quality bit

```{r, eval = FALSE}
qb_extract(x = output, bitfield = newBitfield)
```


## Some background - what is a bitfield, really?

Adding more thoughts about what I had in mind about this code. For MODIS, this is a so-called "bit flag" (or [bit field](https://en.wikipedia.org/wiki/Bit_field)). This is a combination of 0s and 1s that are combined into a binary sequence. It's called bit flag because each position in the sequence is coded by a single bit. R stores each integer as a (huge) 32 bit value, you can check this with `intToBits(x = 2L)` and see how many 0s are used up for that (or actually 00s here, it's just their way of representing a 0) ... But I think we can do way better, by having each single of those 0s be one "switch" that stores particular information, so in the integer `2L` we can store 32 pieces of information, we probably don't even need that many. Depending on how we arrange that information, we'll then get different integers, see the following (32 positions, either 00 or 01):

```
intToBits(x = 0L)
 [1] 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
intToBits(x = 1L)
 [1] 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
intToBits(x = 2L)
 [1] 00 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
intToBits(x = 3L)
 [1] 01 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
```

Using the first two of those bits, we can represent 4 different states of an attribute (00, 01, 10 and 11, or in the R-notation that would be `'00 00'`, `'00 01'`, `'01 00'` and `'01 01'`), with three bits 8 states, etc (2^n)

We could translate the bit-vector, we create, back to an integer and store those integers in a raster-tiff, or a vector for point data and have a giant amount of quality information stored in that single value, which takes up hardly any volume on the hard disc.

It's good that you bring up such information that has several values because I now change the function so that the user can provide the number of bits that shall encode for the quality of a particular attribute. So if we have something like precision and we decided that we want to represent 4 levels, we'd have to specify that we want to use two bits for that. And yeah, the idea was to encode several attributes to be able to select downstream what to weigh more!

Ok, I'll try to implement the country-border check! I am just not sure about the matching with actual landuse/cover information. Which data product should we use for that? I guess ESA LC is not trustworthy enough, right? Would it also make sense to include and propagate the quality metrics you derive for your first chapter in that data structure? Maybe we could already implement that for modelling in LUCKINet, basically, build such a QB-layer based on your metric and use it for weighing modelling by it?




# To Do

- need functionality to build the sequence actually sequentially. For instance, when going through a pipeline, where certain actions are carried out but in different scripts, an old QB from a previous script could be picked up and additional information can be added to it. -> This should be possible with this set-up, but needs to be described explicitly
- needs functionality to have different data structures interact -> I solve this now by transforming rasters to a table that can then be dealt with easily without any generics/methods
- [ ] write qb_grow
  3. this must call the function provided in bit = ... and write the tentative output into a separate environment
- [ ] write qb_combine
- [ ] write qb_extract
- [ ] write bitfield show method
- [ ] write qb_case
- [ ] write qb_filter
- [ ] other pre-made quality flag functions?!
- [ ] write and/or improve documentation
